\documentclass{article} % For LaTeX2e
\usepackage{nips15submit_e,times}
\usepackage[colorlinks,linkcolor=red]{hyperref}
\usepackage{url}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{float}
\usepackage{bm}
\usepackage{amssymb}
%\documentstyle[nips14submit_09,times,art10]{article} % For LaTeX 2.09


\title{CS499 Homework 4}


\author{
	Intersteller\thanks{ Use footnote for providing further information
		about author (webpage, alternative address)---\emph{not} for acknowledging
		funding agencies.}
	Department of Computer Science
	Cranberry-Lemon University
	Pittsburgh, PA 15213
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

%\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}

	\maketitle
	\textbf{Exercise 4.1}\par
	This proof goes wrong when it calculates $E[X_T]$ in a second way. According to this proof, T is a certain number. Thus, after walking T steps, actually we can reach i with probability $Pr[T,i] (i=0,1,2,\cdots ,k)$. And obviously, none of $Pr[T,i]$ equals 0 for a certain T. So we cannot derive the equation $E[X_T] = k\cdot p_j + 0 \cdot (1-p_j)$ .
	If we slightly change the proof, the equation can be derived correctly. We let $T\to \infty$, of course, $${\lim_{T\to \infty}} Pr[T,i]=0 (i=1,2,\cdots ,k-1)$$ $${\lim_{T\to \infty}}Pr[T,k]=P_j$$ $${\lim_{T\to \infty}} Pr[T,0]=1-P_j$$ In this way the equation works.


	\textbf{Exercise 4.2}\par
	\begin{enumerate}
	\item Since $$E(T)=\sum_{n=0}^\infty (2n+1)C_{n}p^{n+1}(1-p)^{n}$$ 
	and
	\begin{align*}
	\sum_{n=0}^\infty (2n+1)C_{n}p^{n+1}(1-p)^{n}&=p\sum_{n=0}^\infty \frac{2n+1}{n+1} \binom{2n}{n}[p(1-p)]^{n}\\
	&<2p\sum_{n=0}^\infty \binom{2n}{n}[p(1-p)]^{n}\\
	&<2p\sum_{n=0}^\infty 2^{2n}[p(1-p)]^{n}\\
	&=2p\sum_{n=0}^\infty [4p(1-p)]^{n}\\
	\end{align*}
	\textbf{where $C_{n}$ is Calatan number.}\par
	we have $$E(T)<2p\sum_{n=0}^\infty [4p(1-p)]^{n}$$
	Since $p>\frac{1}{2}$, then $4p(1-p)<1$.\par
	Thus, $$E(T)<\frac{2p}{1-4p(1-p)}$$ $E(T)$ is finite.
	\item We denote $$g(x)=C_0+C_1x+C_2x^2+...+C_{n}x^{n}+...$$ \textbf{where $C_{n}$ is Calatan number.}\par
	We can compute that $$[g(x)]^2=C_0^2+(C_0C_1+C_1C_0)x+(C_0C_2+C_1^2+C_2C_0)x^2+...+(C_0C_{n}+C_1C_{n-1}+...+C_{n}C_0)x^{n}+...$$
	Since $$C_{n}=C_0C_{n-1}+C_1C_{n-2}+...+C_{n-1}C_0$$
	we have $$[g(x)]^2=C_0^2+C_2x+C_3x^2+C_4x^3+...+C_{n+1}x^{n}+...$$
	Since $C_0=C_1=1$, we have $x[g(x)]^2=g(x)-1$.\par
	We solve the equation and get
	$$g(x)=\frac{1\pm\sqrt{1-4x}}{2x}$$
	Since $g(0)=1$, thus 
	$$g(x)=\frac{1-\sqrt{1-4x}}{2x}$$
	$$g'(x)=\frac{1}{x\sqrt{1-4x}}-\frac{1-\sqrt{1-4x}}{2x^2}$$
	So,
	\begin{align*}
	E(T)&=\sum_{n=0}^\infty (2n+1)C_{n}p^{n+1}(1-p)^{n}\\
	&=2p\sum_{n=0}^\infty nC_{n}[p(1-p)]^{n}+p\sum_{n=0}^\infty C_{n}[p(1-p)]^{n}\\
	&=2p^2(1-p)\times (g[p(1-p)])'+p\times g[p(1-p)]\\
	&=\frac{2p^2(1-p)}{p(1-p)\sqrt{1-4p(1-p)}}-\frac{1-\sqrt{1-4p(1-p)}}{1-p}+p\times \frac{1-\sqrt{1-4p(1-p)}}{2p(1-p)}\\
	&=\frac{2p}{\sqrt{1-4p(1-p)}}-\frac{1-\sqrt{1-4p(1-p)}}{2(1-p)}\\
	&=\frac{2p}{2p-1}-\frac{2(1-p)}{2(1-p)}\\
	&=\frac{1}{2p-1}
	\end{align*}
	\end{enumerate}


	\textbf{Exercise 4.3}\par
	This proof went wrong because when $p<\frac{1}{2}$, $T$ does not have a distribution sequence. As we have already known, $\sum_{i=0}^{\infty} Pr[T=i]=\sum_{n=0}^{\infty} C_n p^{n+1}(1-p)^n<1$, and it fails to satisfy the normalization of a distribution sequence that $\sum_{i=0}^{\infty} Pr[T=i]=1$, so $T$ can never have an expectation.
	
	\textbf{Exercise 4.4}\par
	$$E[\frac{1}{T+1}]=\sum_{n=0}^\infty \frac{1}{2(n+1)}C_{n}p^{n+1}(1-p)^{n}$$
	We denote $$g(x)=C_0+C_1x+C_2x^2+...+C_{n}x^{n}+...$$ \textbf{where $C_{n}$ is Calatan number.}\par
	We can compute that $$[g(x)]^2=C_0^2+(C_0C_1+C_1C_0)x+(C_0C_2+C_1^2+C_2C_0)x^2+...+(C_0C_{n}+C_1C_{n-1}+...+C_{n}C_0)x^{n}+...$$
	Since $$C_{n}=C_0C_{n-1}+C_1C_{n-2}+...+C_{n-1}C_0$$
	we have $$[g(x)]^2=C_0^2+C_2x+C_3x^2+C_4x^3+...+C_{n+1}x^{n}+...$$
	Since $C_0=C_1=1$, we have $x[g(x)]^2=g(x)-1$.\par
	We solve the equation and get
	$$g(x)=\frac{1\pm\sqrt{1-4x}}{2x}$$
	Since $g(0)=1$, thus 
	$$g(x)=\frac{1-\sqrt{1-4x}}{2x}$$
	$$G(x)=\sum_{n=0}^\infty \frac{1}{n+1}C_{n}x^{n+1}=\int_{0}^{x} g(t)dt=\ln(\sqrt{1-4x}+1)-\sqrt{1-4x}-\ln 2+1$$
	Since $p=\frac{1}{2}$, then 
	\begin{align*}
	E[\frac{1}{T+1}]&=\frac{1}{4}\sum_{n=0}^\infty \frac{1}{n+1}C_{n}(\frac{1}{4})^n\\
	&=\sum_{n=0}^\infty \frac{1}{n+1}C_{n}(\frac{1}{4})^{n+1}\\
	&=G(\frac{1}{4})\\
	&=1-\ln 2
	\end{align*}

    \textbf{Exercise 4.5}\par
    $Proof$.
    Suppose $A_i$ whose strength is $a_i$ and $B_j$ whose strength is $b_j$ fight.After fighting,for $A_i$ we have
    $$
    E(strength_{A_i})=\frac{a_i}{a_i+b_j}\cdot (a_i+b_j)+\frac{b_j}{a_i+b_j}\cdot 0=a_i
    $$
    So after $\forall k$ wars,
    $$
    E(\sum strength_{A_i})=\sum_{i=1}^{m}a_i
    $$
    $$
    E(\sum strength_{B_j})=\sum_{j=1}^{n}b_j
    $$
    Now let's compute $E(\sum strength_{A_i})$ in a different way:\par
    Wars has only two results:Alice'team wins or Bob's team wins.\par
    The former happens with probability $p$,
    the latter with probability $1-p$.\par
    Thus
    $$
    E(\sum strength_{A_i})=(\sum_{i=1}^{m}a_i+\sum_{j=1}^{n}b_j)\cdot p+0\cdot (1-p)
    $$
    Therefore,
    $$
    p=\frac{\sum_{i=1}^{m}a_i}{\sum_{i=1}^{m}a_i+\sum_{j=1}^{n}b_j}
    $$
    So the probability of Alice's team winning does not depend on the order in which Alice and Bob send their monsters into the arena.
 
   \textbf{Exercise 4.6}\par
	\textbf{proof} Define Alice's winning probability of an order $\{a_{i_1},a_{i_2},\cdot,a_{i_n}\}$ is $Pr_{i_1i_2 \cdot i_n:m}$,in which m is the number of robots in team B, $p_{ij}=\frac{a_i}{a_i+b_j}$,$q_{ij}=1-p_{ij}$  We use the induction to prove.\\

    \textbf{lemma} Consider there are only two robot in Alice's team(we call it team A) and m in Bob's team(we call it team B), the probability of team A is
    \begin{equation}
     Pr_{12:m}=\frac{q_{12}p_{21}\dots p_{2m}-q_{21}p_{11}\dots p_{1m}}{p_{21}-p_{11}}
    \end{equation}
    We use induction to prove.When $m=2$,we can easily get
    \begin{equation}
    Pr_{12}=Pr_{21}=\frac{a_1a_2+a_1b_2+a_2b_2}{(a_1+b_2)(a_2+b_2)}=\frac{q_{12}p_{21}p_{22}-q_{21}p_{11}p_{12}}{p_{21}-p_{11}}
    \end{equation}
    Assume the lemma is true when m=k-1,then
    \begin{equation}
    \begin{aligned}
    Pr_{12:k}&=p_{11}Pr_{12:k-1}+q_{11}p_{21}\cdots p_{2k}\\
    		 &=p_{11}\cdot \frac{q_{12}p_{22}\dots p_{2k}-q
    		 	_{22}p_{12}\dots p_{1k}}{p_{22}-p_{12}}+q_{11}p_{21}\cdots p_{2k}
    \end{aligned}
    \end{equation}
    Consider that
    $$
    \frac{p_{22}q_{12}}{p_{22}-p_{12}}=\frac{q_{11}p_{21}}{p_{21}-p_{11}}=\frac{a_1}{a_2-a_1}
    $$
    $$
    \frac{p_{12}q_{22}}{p_{22}-p_{12}}=\frac{q_{21}p_{11}}{p_{21}-p_{11}}=\frac{a_2}{a_2-a_1}
    $$
    Plug it into the formula of $Pr$
    $$
    Pr_{12:k}=\frac{q_{12}p_{21}\dots p_{2k}-q_{21}p_{11}\dots p_{1k}}{p_{21}-p_{11}}
    $$
    So the lemma proved true.\\

     Assume that for team B with $m-1$ robots,the winning probability of team A is regardless of the order. \textbf{\romannumeral1}\ Consider team B with $m$ robots, the winning prabability with the order$ \{1,2,3,\cdots,n\}$ is
      \begin{equation}
     \begin{aligned}
     Pr_{123\cdots (n-1)n:m}&=p_{11}Pr_{123\cdots n:(m-1)}+q_{11}Pr_{123\cdots n-1:m}\\
     &=p_{11}Pr_{123\cdots n:(m-1)}+q_{11}p_{21}Pr_{123\cdots n-1:m}+\cdots\\&+q_{11}q_{12}\cdots q_{(n-2)1}p_{(n-1)1}Pr_{(n-1)n:k-1}+q_{11}q{12}\cdots q_{(n-2)1}q_{(n-1)1}Pr_{n:k}
     \end{aligned}
     \end{equation}
     exchange the order of last two robots, the winning prabability is
     \begin{equation}
     \begin{aligned}
     Pr_{123\cdots n(n-1):m}&=p_{11}Pr_{123\cdots n:(m-1)}+q_{11}Pr_{123\cdots n-1:m}\\
     &=p_{11}Pr_{123\cdots n:(m-1)}+q_{11}p_{21}Pr_{123\cdots n-1:m}+\cdots\\&+q_{11}q_{12}\cdots q_{(n-2)1}p_{n1}Pr_{(n(n-1):k-1}+q_{11}q_{12}\cdots q_{(n-2)1}q_{n1}Pr_{n-1:k}
     \end{aligned}
     \end{equation}
    It's observed that only the last 2 terms are different,compare it by subtraction
    $$
    Pr_{123\cdots (n-1)n:m}-Pr_{123\cdots n(n-1):m}
    =q_{11}q_{12}\cdots q_{(n-2)1}(p_{(n-1)1}Pr_{(n-1)n:k-1}+q_{(n-1)1}Pr_{n:k}-p_{n1}Pr_{2n(n-1)k-1}-q_{n1}Pr_{n-1:k})
    $$
    Consider that
    $$
    Pr_{n:k}=p_{n1}p_{n2}\cdots p_{nk}
    $$
    $$
    Pr_{(n-1):k}=p_{(n-1)1}p_{(n-1)2}\cdots p_{(n-1)k}
	$$
	and plug the lemma to rewrite $Pr_{n(n-1):k-1}$ and $Pr_{(n-1)n:k-1}$
	$$
	Pr_{n(n-1):k-1}=Pr_{(n-1)n:k-1}=
	\frac{q_{n1}p_{(n-1)1}\cdots p_{(n-1)k}-q_{(n-1)1}p_{n1}\cdots p_{nk}}{p_{(n-1)1}-p{n1}}
	$$
	then we can get the result
	$$
	Pr_{123\cdots (n-1)n:m}-Pr_{123\cdots n(n-1):m}=0
	$$
	\textbf{\romannumeral2}\ Similarly, when exchanging the order of any 2 robots, we can use the method showed in \textbf{\romannumeral1} \ to prove they have the same winning probability. Thus,the proposition proved true.

	\textbf{Questions}\par
	\textbf{1.}\par
	When we work on Exercise 4.5 \& 4.6, we find an interesting phenomenon.
	In Exercise 4.5, we have proved that the probability of victory only depends on the sum of robots’ strengths. But in 4.6, it does not work. For example, if two teams both have 1 robot with strength 1, obviously probability of victory is 50\%. Then if one team separates the robot into n parts, each part with strength $\frac{1}{n}$, its probability of loss is $(\frac{n}{n+1})^n$ . We can calculate that $$\lim_{n\to \infty}(\frac{n}{n+1})^n=\frac{1}{e}$$  which means one can raise its winning probability by dividing its robot.
	So in 4.6, we cannot use the sum of robots’ strength exclusively as the strength of a team. Then how can we evaluate a team’s strength?\par
\textbf{2.}\par
	How can we deal with problems like Exercise 4.6, with lots of variables and circumstances?



\end{document}
	

